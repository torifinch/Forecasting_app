{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torifinch/Forecasting_app/blob/main/streamlit_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ›’ CorporaciÃ³n Favorita Sales Forecasting App\n",
        "\n",
        "Author: Victoria Finch 2025\n",
        "\n",
        "Welcome to the interactive forecasting app for the **CorporaciÃ³n Favorita Grocery Sales** dataset, built with **Streamlit in Colab**!\n",
        "\n",
        "This app allows you to explore and predict daily item sales for different stores across Ecuador using a trained **XGBoost model**. The predictions incorporate rich historical features including:\n",
        "\n",
        "- âœ… Lag features (e.g., `lag_1`, `lag_7`, `lag_14`)\n",
        "- ðŸ“Š Rolling and expanding statistics\n",
        "- ðŸ“… Calendar features (day of week, holiday flags, bridge days)\n",
        "- ðŸ›¢ï¸ Daily oil prices\n",
        "- ðŸš¨ Outlier detection using Z-score smoothing\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ Features\n",
        "\n",
        "- **Top 10 Best Forecasting Candidates**: Automatically selects store-item pairs with the richest sales history\n",
        "- **Manual selection** of any store and item\n",
        "- **Dynamic item filtering** based on selected store\n",
        "- **Flexible forecasting range**: Choose 7, 14, 30, or 90 days\n",
        "- ðŸ“ˆ **Line chart** and ðŸ“‹ **data table** output\n",
        "- ðŸŽ¯ Fully integrated with Google Drive for model + dataset loading\n",
        "\n",
        "---\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1. Select a forecast target using:\n",
        "   - ðŸ”˜ The Top 10 dropdown\n",
        "   - ðŸ”˜ Store + item combo of your choice\n",
        "2. Choose a forecast start date and horizon\n",
        "3. Click **ðŸ”® Forecast**\n",
        "4. View the predicted sales over time and analyze the output\n",
        "\n",
        "---\n",
        "\n",
        "## Model Info\n",
        "\n",
        "- **Model type**: XGBoost Regressor\n",
        "- **Target variable**: Log-transformed `unit_sales` (with inverse transform applied)\n",
        "- **Training data**: Multi-year daily sales data\n",
        "- **Smoothing logic**: Detects and handles statistical outliers to reduce forecast distortion\n",
        "\n",
        "---\n",
        "\n",
        "Letâ€™s dive into the data and forecast the future of Ecuadorâ€™s grocery sales: Just click Run all and then click the Cloudflare Tunnel Link to begin!\n"
      ],
      "metadata": {
        "id": "N22fZsz0a7Cl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOza6HO8tjbZ"
      },
      "source": [
        "## Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfOMrx_BcuGN",
        "outputId": "b1ac6cd7-51cb-472f-e663-6bb11893da92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudflared\n",
            "  Downloading cloudflared-1.0.0.2.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setuptools_scm (from cloudflared)\n",
            "  Downloading setuptools_scm-8.3.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from setuptools_scm->cloudflared) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from setuptools_scm->cloudflared) (75.2.0)\n",
            "Downloading setuptools_scm-8.3.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m839.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cloudflared\n",
            "  Building wheel for cloudflared (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cloudflared: filename=cloudflared-1.0.0.2-py3-none-any.whl size=2983 sha256=b544b331735fe68bed585c471276b811b155f2dd10dc3982ece3b7133f05c198\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/9f/f1/ef5e36c9386d737ac05ab8714d611c430d79abe55d862ca2b7\n",
            "Successfully built cloudflared\n",
            "Installing collected packages: setuptools_scm, cloudflared\n",
            "Successfully installed cloudflared-1.0.0.2 setuptools_scm-8.3.1\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q\n",
        "!pip install cloudflared\n",
        "!pip install gdown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMsfHYNXt0Kx"
      },
      "source": [
        "## Add the cloudfare files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ngy-J0X5tCGK"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t55B0H3xt8cq"
      },
      "source": [
        "## Streamlit App code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gdown\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- File Setup ---\n",
        "DATA_PATH = \"data/\"\n",
        "MODEL_PATH = \"model/\"\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# --- Google Drive File IDs ---\n",
        "DRIVE_FILES = {\n",
        "    \"train\": (\"1fmwyk3G50Iqmb9ywRlynaGrrC1njWBGx\", os.path.join(DATA_PATH, \"train.csv\")),\n",
        "    \"oil\": (\"1YF4BZvIM1W5b5jAauyKIlDEiYayN6rk1\", os.path.join(DATA_PATH, \"oil.csv\")),\n",
        "    \"holidays\": (\"1-77ktGfQ7h7lb0U9Pp3GRTjl0jchpWVL\", os.path.join(DATA_PATH, \"holidays.csv\")),\n",
        "    \"model\": (\"11qoHWIDLEM1GDVtGS2MnwpjPsKfIHazs\", os.path.join(MODEL_PATH, \"xgb_model.pkl\"))\n",
        "}\n",
        "\n",
        "# --- Download Function ---\n",
        "def download_files():\n",
        "    for _, (file_id, path) in DRIVE_FILES.items():\n",
        "        if not os.path.exists(path):\n",
        "            gdown.download(id=file_id, output=path, quiet=False)\n",
        "\n",
        "# --- Preprocessing Function ---\n",
        "def preprocess_input(store_id, item_id, date, df_train, df_oil, df_holidays):\n",
        "    date = pd.to_datetime(date)\n",
        "    history = df_train[(df_train.store_nbr == store_id) & (df_train.item_nbr == item_id)]\n",
        "    history = history[history.date < date].sort_values(\"date\")\n",
        "\n",
        "    if len(history) < 7:\n",
        "        st.warning(f\"âš ï¸ Not enough history for store {store_id}, item {item_id} on {date.date()}. Found only {len(history)} records.\")\n",
        "\n",
        "    unit_sales = history.unit_sales.tail(30).tolist()\n",
        "    last_row = history.tail(1)\n",
        "\n",
        "    lag_1 = last_row.unit_sales.values[0] if not last_row.empty else 0\n",
        "    mean_30 = pd.Series(unit_sales[-30:]).mean() if len(unit_sales) >= 30 else 0\n",
        "    std_30 = pd.Series(unit_sales[-30:]).std() if len(unit_sales) >= 30 else 0\n",
        "\n",
        "    # Z-score and smoothing\n",
        "    z_score = (lag_1 - mean_30) / std_30 if std_30 else 0\n",
        "    is_outlier = z_score > 5\n",
        "    if is_outlier:\n",
        "        lag_1 = pd.Series(unit_sales[-7:]).mean() if len(unit_sales) >= 7 else mean_30\n",
        "\n",
        "    # Oil price fill\n",
        "    oil_df = df_oil.set_index(\"date\").sort_index()\n",
        "    oil_df = oil_df.reindex(pd.date_range(oil_df.index.min(), oil_df.index.max())).ffill().bfill().fillna(0)\n",
        "    oil_price = oil_df.loc[date][\"dcoilwtico\"] if date in oil_df.index else 0\n",
        "\n",
        "    # Holiday checks\n",
        "    holiday_dates = pd.to_datetime(df_holidays.date)\n",
        "    is_holiday = date in holiday_dates\n",
        "    is_day_before = (date + pd.Timedelta(days=1)) in holiday_dates\n",
        "    is_bridge = (date.weekday() == 0 and (date - pd.Timedelta(days=3)) in holiday_dates)\n",
        "\n",
        "    return pd.DataFrame([{\n",
        "        \"id\": 1,\n",
        "        \"store_nbr\": store_id,\n",
        "        \"item_nbr\": item_id,\n",
        "        \"onpromotion\": 0,\n",
        "        \"year\": date.year,\n",
        "        \"month\": date.month,\n",
        "        \"day\": date.day,\n",
        "        \"day_of_week\": date.dayofweek,\n",
        "        \"week_of_year\": date.isocalendar().week,\n",
        "        \"is_weekend\": date.weekday() >= 5,\n",
        "        \"is_holiday\": is_holiday,\n",
        "        \"is_bridge_day\": is_bridge,\n",
        "        \"is_day_before_holiday\": is_day_before,\n",
        "        \"expanding_mean\": history.unit_sales.expanding().mean().iloc[-1] if not history.empty else 0,\n",
        "        \"oil_price\": oil_price,\n",
        "        \"rolling_mean_7d\": pd.Series(unit_sales[-7:]).mean() if len(unit_sales) >= 7 else 0,\n",
        "        \"rolling_mean_14d\": pd.Series(unit_sales[-14:]).mean() if len(unit_sales) >= 14 else 0,\n",
        "        \"rolling_mean_30d\": mean_30,\n",
        "        \"rolling_std_7d\": pd.Series(unit_sales[-7:]).std() if len(unit_sales) >= 7 else 0,\n",
        "        \"rolling_std_14d\": pd.Series(unit_sales[-14:]).std() if len(unit_sales) >= 14 else 0,\n",
        "        \"rolling_std_30d\": std_30,\n",
        "        \"lag_1\": lag_1,\n",
        "        \"lag_7\": unit_sales[-7] if len(unit_sales) >= 7 else 0,\n",
        "        \"lag_14\": unit_sales[-14] if len(unit_sales) >= 14 else 0,\n",
        "        \"z_score\": z_score,\n",
        "        \"is_outlier\": is_outlier\n",
        "    }])\n",
        "\n",
        "# --- Streamlit App ---\n",
        "def main():\n",
        "    st.title(\"Grocery Sales Forecast - CorporaciÃ³n Favorita\")\n",
        "\n",
        "    download_files()\n",
        "\n",
        "    df_train = pd.read_csv(DRIVE_FILES[\"train\"][1], parse_dates=[\"date\"])\n",
        "    df_oil = pd.read_csv(DRIVE_FILES[\"oil\"][1], parse_dates=[\"date\"])\n",
        "    df_holidays = pd.read_csv(DRIVE_FILES[\"holidays\"][1], parse_dates=[\"date\"])\n",
        "\n",
        "    with open(DRIVE_FILES[\"model\"][1], \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    st.sidebar.header(\"Forecast Settings\")\n",
        "\n",
        "    use_top_10 = st.sidebar.checkbox(\"Use Top 10 Best Forecasting Candidates\", value=True) # Top 10 Checkbox\n",
        "\n",
        "    if use_top_10:\n",
        "        combo_counts = df_train.groupby(['store_nbr', 'item_nbr']).size().reset_index(name='count')\n",
        "        top_combos = combo_counts.sort_values('count', ascending=False).head(10)\n",
        "        top_combo_labels = top_combos.apply(lambda row: f\"Store {int(row['store_nbr'])} - Item {int(row['item_nbr'])}\", axis=1)\n",
        "        selected_label = st.sidebar.selectbox(\"Top 10 Combos\", top_combo_labels)\n",
        "        selected_store = int(selected_label.split()[1])\n",
        "        selected_item = int(selected_label.split()[-1])\n",
        "    else:\n",
        "        selected_store = st.sidebar.selectbox(\"Select Store\", sorted(df_train.store_nbr.unique()))\n",
        "        store_items = df_train[df_train.store_nbr == selected_store].item_nbr.unique()\n",
        "        selected_item = st.sidebar.selectbox(\"Select Item\", sorted(store_items))\n",
        "\n",
        "    start_date = st.sidebar.date_input(\"Forecast Start Date\", datetime(2014, 1, 1))\n",
        "    days = st.sidebar.selectbox(\"Forecast Horizon (in days)\", [7, 14, 30, 90])\n",
        "\n",
        "    if st.button(\"ðŸ”® Forecast\"):\n",
        "        forecast_dates = pd.date_range(start=start_date, periods=days)\n",
        "        inputs = pd.concat([\n",
        "            preprocess_input(selected_store, selected_item, d, df_train, df_oil, df_holidays)\n",
        "            for d in forecast_dates\n",
        "        ], ignore_index=True)\n",
        "\n",
        "        preds = model.predict(inputs)\n",
        "        forecast_df = pd.DataFrame({\n",
        "          \"date\": forecast_dates,\n",
        "          \"predicted_sales\": preds\n",
        "        })\n",
        "\n",
        "        # Format the date to remove the time\n",
        "        forecast_df[\"date\"] = forecast_df[\"date\"].dt.date\n",
        "\n",
        "        st.write(f\"Forecasting from {forecast_dates[0].date()} to {forecast_dates[-1].date()}\")\n",
        "        st.write(f\"Store {selected_store} - Item {selected_item}\")\n",
        "\n",
        "        st.subheader(\"Forecast Chart\")\n",
        "        st.line_chart(forecast_df.set_index(\"date\"))\n",
        "\n",
        "        st.subheader(\"Forecast Table\")\n",
        "        st.dataframe(forecast_df.style.format({\"predicted_sales\": \"{:.2f}\"}))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX6VRUmZV3fG",
        "outputId": "e98ff01c-9dfc-40ae-dbcb-ba6e46f7e9f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5wD2k-guLyO"
      },
      "source": [
        "## Run streamlit in the background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ijcMKRBZrsaw"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &> logs.txt &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_c8ihrpuqcR"
      },
      "source": [
        "## Create a Cloudfare Tunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82yhbQnLsNaS",
        "outputId": "6e2a510c-b718-4510-d433-febb737ef77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-05-18T10:45:51Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-05-18T10:45:51Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m |  https://torture-challenge-joins-mark.trycloudflare.com                                    |\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.5.0 (Checksum a62266fd02041374f1fca0d85694aafdf7e26e171a314467356b471d4ebb2393)\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.10, GoArch: amd64\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 3361a410-4f19-4797-ae36-5c30bc4cdaad\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [CurveID(4588) CurveID(25497) CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53\n",
            "2025/05/18 10:45:54 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-05-18T10:45:54Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m73846bbf-218a-48d5-bf26-af8d425cb9bc \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.53 \u001b[36mlocation=\u001b[0matl08 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ],
      "source": [
        "!./cloudflared tunnel --url http://localhost:8501\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho2TQIDeaTLG"
      },
      "source": [
        "When your app works as you expect, you can now paste your app code to the files and upload all of the files to a remote repository!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01v_pyVpAQyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}